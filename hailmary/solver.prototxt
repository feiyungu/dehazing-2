# training set size: T (2569)
# training batch size: Tb (assuming 32)
# validation set size: V (286)
# validation batch size: Vb (assuming 32)

net: "train_val.prototxt"
test_iter: 9           # V / Vb to cover entire validation set
test_interval: 80     # how often to validate
max_iter: 4000         # #epochs * (T / Tb) 
iter_size: 1            # accumulate gradients over iter_size * Tb
base_lr: 0.0001        # base learning rate
lr_policy: "step"       # drop lr in step sizes indicated by gamma
gamma: 0.1              # base_lr * gamma
stepsize: 240        # how often to drop lr
display: 10
momentum: 0.9
weight_decay: 0.0001
snapshot: 100
snapshot_prefix: "models/model"
solver_mode: CPU
